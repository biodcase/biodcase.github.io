# Submission information
submission:
  # Submission label
  # Label is used to index submissions, to avoid overlapping codes among submissions
  # use following way to form your label:
  # [Last name of corresponding author]_[Abbreviation of institution of the corresponding author]_task[task number]_[index number of your submission (1-4)]
  label: Cartwright_NYU_task5_1

  # Submission name
  # This name will be used in the results tables when space permits
  name: DCASE2020 baseline system

  # Submission name abbreviated
  # This abbreviated name will be used in the results table when space is tight, maximum 10 characters
  abbreviation: Baseline

  # Submission authors in order, mark one of the authors as corresponding author.
  authors:
    # First author
    - firstname: Mark
      lastname: Cartwright
      email: mark.cartwright@nyu.edu                 # Contact email address
      corresponding: true                         # Mark true for one of the authors
      # Affiliation information for the author
      affiliation:
        institution: New York University
        department: Music and Audio Research Laboratory, Department of Computer Science and Engineering, Center for Urban Science and Progress
        location: New York, New York, USA

    # Second author
    - firstname: Jason
      lastname: Cramer
      # Affiliation information for the author
      affiliation:
        institution: New York University
        department: Music and Audio Research Laboratory, Department of Electrical and Computer Engineering
        location: New York, New York, USA

    # Third author
    - firstname: Ana Elisa
      lastname: Mendez Mendez
      # Affiliation information for the author
      affiliation:
        institution: New York University
        department: Music and Audio Research Laboratory, Department of Music and Performing Arts Professions
        location: New York, New York, USA

    # Fourth author
    - firstname: Yu
      lastname: Wang
      # Affiliation information for the author
      affiliation:
        institution: New York University
        department: Music and Audio Research Laboratory, Department of Music and Performing Arts Professions
        location: New York, New York, USA

    # Fifth author
    - firstname: Ho-Hsiang
      lastname: Wu
      # Affiliation information for the author
      affiliation:
        institution: New York University
        department: Music and Audio Research Laboratory, Department of Music and Performing Arts Professions
        location: New York, New York, USA

    # Sixth author
    - firstname: Vincent
      lastname: Lostanlen
      # Affiliation information for the author
      affiliation:
        institution: Cornell University
        department: Cornell Lab of Ornithology
        location: Ithaca, New York, USA

    # Seventh author
    - firstname: Magdalena
      lastname: Fuentes
      # Affiliation information for the author
      affiliation:
        institution: New York University
        department: Music and Audio Research Laboratory, Department of Music and Performing Arts Professions
        location: New York, New York, USA

    # Eigth author
    - firstname: Justin
      lastname: Salamon
      # Affiliation information for the author
      affiliation:
        institution: Adobe Research
        department: Machine Perception Team
        location: San Francisco, CA, USA

    # Ninth author
    - firstname: Juan P.
      lastname: Bello
      # Affiliation information for the author
      affiliation:
        institution: New York University
        department: Music and Audio Research Laboratory, Department of Computer Science and Engineering, Center for Urban Science and Progress
        location: New York, New York, USA


# System information
system:
  # System description, meta data provided here will be used to do
  # meta analysis of the submitted system. Use general level tags, if possible use the tags provided in comments.
  # If information field is not applicable to the system, use "!!null".
  description:

    # Audio input
    input_channels: mono                  # e.g. one or multiple [mono, binaural, left, right, mixed, ...]
    input_sampling_rate: 48kkHz            #

    # Acoustic representation
    acoustic_features: openl3   # e.g one or multiple [MFCC, log-mel energies, spectrogram, CQT, deep embedding (e.g. vggish), ...]

    # Data augmentation methods
    data_augmentation: !!null             # [time stretching, block mixing, pitch shifting, ...]

    # Machine learning method
    # In case using ensemble methods, please specify all methods used (comma separated list).
    # You do not need to repeat model types used multiple times in the ensemble.
    machine_learning_method: MLP          # e.g one or multiple [GMM, HMM, kNN, MLP, CNN, RNN, CRNN, NMF, random forest, ensemble, ...]

    # Ensemble method subsystem count
    # In case ensemble method is not used, mark !!null.
    ensemble_method_subsystem_count: !!null # [2, 3, 4, 5, ... ]

    # Specify if any of the additional metadata was used for training
    used_annotator_id: false
    used_proximity: false
    used_sensor_id: false
    used_borough: false
    used_block: false
    used_latitude: true
    used_longitude: true
    used_year: false
    used_week: true
    used_day: true
    used_hour: true

    # Method for aggregating predictions over time, if relevant
    aggregation_method: !!null               # [mean, ...]

    # STC data type and source
    stc_external_data_and_sources: !!null # [(precipitation, NOAA), (temperature, NOAA), (311complaints, NYCOpenData), ...]

    # External data type and source
    other_external_data_and_sources: !!null # [(audio_data,  AudioSet), ...]

    # Annotation level targeted by model
    # That is, if the model only predicts fine level annotations
    # should be specified as "fine". A model that is specifically
    # trained to predict both fine and coarse annotations should
    # be specified as "both".
    target_level: fine                      # [fine, coarse, both]

    # Method for determining targets for training from annotations
    target_method: minority vote          # [minority vote, majority vote, ...]

    # Re-labeling of the train set
    re_labeling: !!null                  # [automatic, manual, ...]

    # NOTE: These should only be provided if providing detections, rather than
    # probabilities of class presence.
    #
    # Type of method used to determine detection thresholds
    detection_threshold_method: !!null     # [automatic, manual, fixed, !!null]
    # Specify if the method for determining threshold was done over all classes
    # or per class
    detection_threshold_level: !!null     # [global, classwise, !!null]

  # System complexity, meta data provided here will be used to evaluate
  # submitted systems from the computational load perspective.
  complexity:

    # Total amount of learned parameters used in the acoustic model.
    # For neural networks, this information is usually given before training process
    # in the network summary. For other than neural networks, if parameter count
    # information is not directly available,try estimating the count as accurately
    # as possible. In case of ensemble approaches, add up parameters for all subsystems.
    total_parameters: 79534

  # URL to the source code of the system
  source_code: https://github.com/sonyc-project/dcase2020task5-uststc-baseline
