# Submission information
submission:
  # Submission label
  # Label is used to index submissions.
  # Generate your label following way to avoid
  # overlapping codes among submissions:
  # [Last name of corresponding author]_[Abbreviation of institute of the corresponding author]_task[task number]_[index number of your submission (1-4)]
  label: Heittola_TAU_task1a_1

  # Submission name
  # This name will be used in the results tables when space permits
  name: DCASE2020 baseline system

  # Submission name abbreviated
  # This abbreviated name will be used in the results table when space is tight.
  # Use maximum 10 characters.
  abbreviation: Baseline

  # Authors of the submitted system. Mark authors in
  # the order you want them to appear in submission lists.
  # One of the authors has to be marked as corresponding author,
  # this will be listed next to the submission in the results tables.
  authors:
    # First author
    - lastname: Heittola
      firstname: Toni
      email: toni.heittola@tuni.fi                # Contact email address
      corresponding: true                         # Mark true for one of the authors

      # Affiliation information for the author
      affiliation:
        abbreviation: TAU
        institute: Tampere University
        department: Computing Sciences            # Optional
        location: Tampere, Finland

    # Second author
    - lastname: Mesaros
      firstname: Annamaria
      email: annamaria.mesaros@tuni.fi

      # Affiliation information for the author
      affiliation:
        abbreviation: TAU
        institute: Tampere University
        department: Computing Sciences
        location: Tampere, Finland

    # Third author
    - lastname: Virtanen
      firstname: Tuomas
      email: tuomas.virtanen@tuni.fi

      # Affiliation information for the author
      affiliation:
        abbreviation: TAU
        institute: Tampere University
        department: Computing Sciences
        location: Tampere, Finland

# System information
system:
  # System description, meta data provided here will be used to do
  # meta analysis of the submitted system.
  # Use general level tags, when possible use the tags provided in comments.
  # If information field is not applicable to the system, use "!!null".
  description:

    # Audio input
    # e.g. 16kHz, 22.05kHz, 44.1kHz
    input_sampling_rate: 44.1kHz

    # Acoustic representation
    # one or multiple labels, e.g. MFCC, log-mel energies, spectrogram, CQT, raw waveform, ...
    acoustic_features: !!null

    # Embeddings
    # e.g. VGGish, OpenL3, ...
    embeddings: OpenL3

    # Data augmentation methods
    # e.g. mixup, time stretching, block mixing, pitch shifting, ...
    data_augmentation: !!null

    # Machine learning
    # In case using ensemble methods, please specify all methods used (comma separated list).
    # one or multiple, e.g. GMM, HMM, SVM, MLP, CNN, RNN, CRNN, ResNet, ensemble, ...
    machine_learning_method: MLP

    # Ensemble method subsystem count
    # In case ensemble method is not used, mark !!null.
    # e.g. 2, 3, 4, 5, ...
    ensemble_method_subsystem_count: !!null

    # Decision making methods
    # e.g. average, majority vote, maximum likelihood, ...
    decision_making: !!null

    # External data usage method
    # e.g. directly, embeddings, pre-trained model, ...
    external_data_usage: embeddings

  # System complexity, meta data provided here will be used to evaluate
  # submitted systems from the computational load perspective.
  complexity:
    # Total amount of parameters used in the acoustic model.
    # For neural networks, this information is usually given before training process
    # in the network summary.
    # For other than neural networks, if parameter count information is not directly
    # available, try estimating the count as accurately as possible.
    # In case of ensemble approaches, add up parameters for all subsystems.
    # In case embeddings are used, add up parameter count of the embedding
    # extraction networks and classification network
    # Use numerical value.
    total_parameters: 5012931 # embeddings (OpenL2)=4684224, classifier=328707

  # List of external datasets used in the submission.
  # Development dataset is used here only as example, list only external datasets
  external_datasets:
    # Dataset name
    - name: TAU Urban Acoustic Scenes 2020, Development dataset

      # Dataset access url
      url: https://doi.org/10.5281/zenodo.3819968

      # Total audio length in minutes
      total_audio_length: 3840            # minutes

  # URL to the source code of the system [optional]
  source_code: https://github.com/toni-heittola/dcase2020_task1_baseline

# System results
results:
  development_dataset:
    # System results for development dataset with provided the cross-validation setup.
    # Full results are not mandatory, however, they are highly recommended
    # as they are needed for through analysis of the challenge submissions.
    # If you are unable to provide all results, also incomplete
    # results can be reported.

    # Overall metrics
    overall:
      accuracy: 51.6    # mean of class-wise accuracies
      logloss: 1.405

    # Class-wise metrics
    class_wise:
      airport:
        accuracy: 36.5
        logloss: 1.989
      bus:
        accuracy: 52.9
        logloss: 1.014
      metro:
        accuracy: 46.8
        logloss: 1.429
      metro_station:
        accuracy: 47.1
        logloss: 1.477
      park:
        accuracy: 72.7
        logloss: 0.971
      public_square:
        accuracy: 59.6
        logloss: 1.182
      shopping_mall:
        accuracy: 42.4
        logloss: 1.714
      street_pedestrian:
        accuracy: 20.9
        logloss: 2.421
      street_traffic:
        accuracy: 74.7
        logloss: 0.861
      tram:
        accuracy: 62.8
        logloss: 0.989

    # Device-wise
    device_wise:
      a:
        accuracy: 68.8
        logloss: 0.946
      b:
        accuracy: 60.2
        logloss: 1.158
      c:
        accuracy: 59.9
        logloss: 1.038
      s1:
        accuracy: 50.3
        logloss: 1.408
      s2:
        accuracy: 50.0
        logloss: 1.405
      s3:
        accuracy: 50.9
        logloss: 1.468
      s4:
        accuracy: 45.2
        logloss: 1.642
      s5:
        accuracy: 44.8
        logloss: 1.646
      s6:
        accuracy: 34.8
        logloss: 1.931
