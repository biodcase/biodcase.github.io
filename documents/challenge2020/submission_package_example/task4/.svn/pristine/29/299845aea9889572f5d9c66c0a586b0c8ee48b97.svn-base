# Submission information
submission:
  # Submission label
  # Label is used to index submissions, to avoid overlapping codes among submissions
  # use following way to form your label:
  # [Last name of corresponding author]_[Abbreviation of institute of the corresponding author]_task[task number]_[index number of your submission (1-4)]
  label: Turpault_INR_task4_SS_SED_1

  # Submission name
  # This name will be used in the results tables when space permits
  name: DCASE2020 SS+SED baseline system

  # Submission name abbreviated
  # This abbreviated name will be used in the results table when space is tight, maximum 10 characters
  abbreviation: SS+SED Baseline

  # Submission authors in order, mark one of the authors as corresponding author.
  authors:
    # First author
    - lastname: Turpault
      firstname: Nicolas
      email: nicolas.turpault@inria.fr                # Contact email address
      corresponding: true                             # Mark true for one of the authors

      # Affiliation information for the author
      affiliation:
        abbreviation: INR
        institute: Inria Nancy Grand-Est
        department: Department of Natural Language Processing & Knowledge Discovery
        location: Nancy, France

    # Second author
    - lastname: Serizel
      firstname: Romain
      email: romain.serizel@loria.fr                  # Contact email address


      # Affiliation information for the author
      affiliation:
        abbreviation: ULO
        institute: University of Lorraine, Loria
        department: Department of Natural Language Processing & Knowledge Discovery
        location: Nancy, France

    # Third author
    -   firstname: John
        lastname: Hershey

      # Affiliation information for the author
        affiliation:
          abbreviation: GOO
          institue: Google, Inc.
          department: AI Perception
          Location: Cambridge, United States

    # Fourth author
    - firstname: Scott
      lastname: Wisdom

    # Affiliation information for the author
      affiliation:
        abbreviation: GOO
        institue: Google, Inc.
        department: AI Perception
        Location: Cambridge, United States

    # Fifth author
    - firstname: Hakan
      lastname: Erdogan

    # Affiliation information for the author
      affiliation:
        abbreviation: GOO
        institue: Google, Inc.
        department: AI Perception
        Location: Cambridge, United States

        #...



# SED System information
sed_system:
  # SED system description, meta data provided here will be used to do
  # meta analysis of the submitted system. Use general level tags, if possible use the tags provided in comments.
  # If information field is not applicable to the system, use "!!null".
  description:

    # Audio input
    input_channels: mono                  # e.g. one or multiple [mono, binaural, left, right, mixed, ...]
    input_sampling_rate: 16               # In kHz

    # Acoustic representation
    acoustic_features: log-mel energies   # e.g one or multiple [MFCC, log-mel energies, spectrogram, CQT, ...]

    # Data augmentation methods
    data_augmentation: !!null             # [time stretching, block mixing, pitch shifting, ...]

    # Machine learning
    # In case using ensemble methods, please specify all methods used (comma separated list).
    machine_learning_method: CRNN         # e.g one or multiple [GMM, HMM, SVM, kNN, MLP, CNN, RNN, CRNN, NMF, random forest, ensemble, ...]

    # Ensemble method subsystem count
    # In case ensemble method is not used, mark !!null.
    ensemble_method_subsystem_count: 3 # [2, 3, 4, 5, ... ]

    # Decision making methods
    decision_making: P-norm                 # [majority vote, ...]

    # Semi-supervised method used to exploit both labelled and unlabelled data
    machine_learning_semi_supervised: mean-teacher student         # e.g one or multiple [pseudo-labelling, mean-teacher student...]

    # Segmentation method
    segmentation_method: !!null					            # E.g. [RBM, attention layers...]

    # Post-processing, followed by the time span (in ms) in case of smoothing
    post-processing: median filtering (93ms)				# [median filtering, time aggregation...]

  # System complexity, meta data provided here will be used to evaluate
  # submitted systems from the computational load perspective.
  complexity:

    # Total amount of parameters used in the acoustic model. For neural networks, this
    # information is usually given before training process in the network summary.
    # For other than neural networks, if parameter count information is not directly available,
    # try estimating the count as accurately as possible.
    # In case of ensemble approaches, add up parameters for all subsystems.
    total_parameters: 1112420
    # Approximate training time followed by the hardware used
    trainining_time: 3h (1 GTX 1080 Ti)
    # Model size in MB
    model_size: 4.5


  # The training subsets used to train the model. Followed the amount of data (number of clips) used per subset.
  subsets: 				# [weak (xx), unlabel_in_domain (xx), synthetic (xx), FUSS (xx)...]

  # URL to the source code of the system [optional, highly recommended]
  source_code: https://github.com/turpaultn/dcase20_task4/tree/public_branch/baseline

# SS System information
ss_system:
  # SS system description, meta data provided here will be used to do
  # meta analysis of the submitted system. Use general level tags, if possible use the tags provided in comments.
  # If information field is not applicable to the system, use "!!null".
  # Description of sound separation system (optional).

  input_sampling_rate: 16       #in kHz

  # Basis
  basis: stft   # e.g one or multiple [stft, learnable_conv, ...]

  # Data augmentation methods
  data_augmentation: !!null             # [time stretching, block mixing, pitch shifting, mix-on-the-fly, ...]

  # Network architecture
  # In case using ensemble methods, please specify all methods used (comma separated list).
  network_architecture: TDCN++         # e.g one or multiple [MLP, CNN, RNN, CRNN, NMF, ConvTasNet, TDCN++, ensemble, ...]

  # Ensemble method subsystem count
  # In case ensemble method is not used, mark !!null.
  ensemble_method_subsystem_count: !!null # [2, 3, 4, 5, ... ]

  # Other details about the separation model
  other_details: mixture consistency   # comma-delimted

  complexity:

    # Total amount of parameters used in the acoustic model. For neural networks, this
    # information is usually given before training process in the network summary.
    # For other than neural networks, if parameter count information is not directly available,
    # try estimating the count as accurately as possible.
    # In case of ensemble approaches, add up parameters for all subsystems.
    total_parameters: 1112420
    # Approximate training time followed by the hardware used
    trainining_time: 3h (1 GTX 1080 Ti)
    # Model size in MB
    model_size: 4.5

  # URL to the source code of the system [optional, highly recommended]
  source_code: https://github.com/google-research/sound-separation/tree/master/models/dcase2020_fuss_baseline

# Description of joint SED ans SS system.
sed_ss_description:
    # Integration type
    integration_type: late         # [early, late, both,...]

    # Integration method
    integration_method: average    # [average, concat, ...]

    # Separated sources used
    separated_sources_used: DESED foreground  # [DESED foreground, all sources, ...]

    # Training procedure
    training: separately           # [separately, end-to-end, ...]



# System results (SED)
sed_results:
  # Full results are not mandatory, but for through analysis of the challenge submissions recommended.
  # If you cannot provide all results, also incomplete results can be reported.
  development_dataset:
    # System result for development dataset with provided the cross-validation setup.
    overall:
      F-score: 34.8
      PSDS: 0.610

    # Class-wise accuracies
    class_wise:
      Alarm_bell_ringing:
        F-score: 36.1
      Blender:
        F-score: 35.2
      Cat:
        F-score: 45.1
      Dishes:
        F-score: 25.7
      Dog:
        F-score: 22.1
      Electric_shaver_toothbrush:
        F-score: 37.6
      Frying:
        F-score: 24.1
      Running_water:
        F-score: 33.4
      Speech:
        F-score: 50.9
      Vacuum_cleaner:
        F-score: 45.7


# System results (see SS evaluation script for more details)
ss_results:
  # SS on DESED+FUSS development set
  dry_fuss_development_dataset:
    SISNR_mixture_target: 0
    SISNR_separated_target: 0
    SISNR_mixture_background: 0
    SISNR_separated_background: 0

  # SS on DESED+FUSS evaluation set
  dry_fuss_evaluation_dataset:
    SISNR_mixture_target: 0
    SISNR_separated_target: 0
    SISNR_mixture_background: 0
    SISNR_separated_background: 0
