# Submission information
submission:
  # Submission label
  # Label is used to index submissions, to avoid overlapping codes among submissions
  # use following way to form your label:
  # [Last name of corresponding author]_[Abbreviation of institute of the corresponding author]_task[task number]_[index number of your submission (1-4)]
  label: Heittola_TUT_task1b_1

  # Submission name
  # This name will be used in the results tables when space permits
  name: DCASE2018 baseline system

  # Submission name abbreviated
  # This abbreviated name will be used in the results table when space is tight, maximum 10 characters
  abbreviation: Baseline

  # Submission authors in order, mark one of the authors as corresponding author.
  authors:
    # First author
    - lastname: Heittola
      firstname: Toni
      email: toni.heittola@tut.fi                     # Contact email address
      corresponding: true                             # Mark true for one of the authors

      # Affiliation information for the author
      affiliation:
        abbreviation: TUT
        institute: Tampere University of Technology
        department: Laboratory of Signal Processing
        location: Tampere, Finland

    - lastname: Mesaros
      firstname: Annamaria
      email: annamaria.mesaros@tut.fi                 # Contact email address

      # Affiliation information for the author
      affiliation:
        abbreviation: TUT
        institute: Tampere University of Technology
        department: Laboratory of Signal Processing
        location: Tampere, Finland

# System information
system:
  # System description, meta data provided here will be used to do
  # meta analysis of the submitted system. Use general level tags, if possible use the tags provided in comments.
  # If information field is not applicable to the system, use "!!null".
  description:

    # Audio input
    input_sampling_rate: 48kHz            #

    # Acoustic representation
    acoustic_features: log-mel energies   # e.g one or multiple [MFCC, log-mel energies, spectrogram, CQT, ...]

    # Data augmentation methods
    data_augmentation: !!null             # [time stretching, block mixing, pitch shifting, ...]

    # Machine learning
    # In case using ensemble methods, please specify all methods used (comma separated list).
    machine_learning_method: CNN          # e.g one or multiple [GMM, HMM, SVM, kNN, MLP, CNN, RNN, CRNN, NMF, random forest, ensemble, ...]

    # Ensemble method subsystem count
    # In case ensemble method is not used, mark !!null.
    ensemble_method_subsystem_count: !!null # [2, 3, 4, 5, ... ]

    # Decision making methods
    decision_making: !!null               # [majority vote, ...]

    # Method to deal with mismatched devices
    device_mismatch_handling: !!null      #

  # System complexity, meta data provided here will be used to evaluate
  # submitted systems from the computational load perspective.
  complexity:

    # Total amount of parameters used in the acoustic model. For neural networks, this
    # information is usually given before training process in the network summary.
    # For other than neural networks, if parameter count information is not directly available,
    # try estimating the count as accurately as possible.
    # In case of ensemble approaches, add up parameters for all subsystems.
    total_parameters: 116118

  # URL to the source code of the system [optional]
  source_code: https://github.com/DCASE-REPO/dcase2018_baseline/tree/master/task1

# System results
results:
  # Full results are not mandatory, but for through analysis of the challenge submissions recommended.
  # If you cannot provide all results, also incomplete results can be reported.

  development_dataset:
    # System result for development dataset with provided the cross-validation setup.
    # Overall accuracy, average accuracy between device B and C (average of average class-wise accuracy)
    overall:
      accuracy: 45.6

    # Class-wise accuracies
    class_wise:
      airport:
        accuracy: 72.5
      bus:
        accuracy: 78.3
      metro:
        accuracy: 20.6
      metro_station:
        accuracy: 32.8
      park:
        accuracy: 59.2
      public_square:
        accuracy: 24.7
      shopping_mall:
        accuracy: 61.1
      street_pedestrian:
        accuracy: 20.8
      street_traffic:
        accuracy: 66.4
      tram:
        accuracy: 19.7

    device_wise:
      # Device wise results, three devices: A, B, C

      device_A:
        # Overall accuracy, device A (mean of class-wise accuracies)
        overall:
          accuracy: 58.9

        # Class-wise accuracies
        class_wise:
          airport:
            accuracy: 73.4
          bus:
            accuracy: 56.7
          metro:
            accuracy: 46.6
          metro_station:
            accuracy: 52.9
          park:
            accuracy: 80.8
          public_square:
            accuracy: 37.9
          shopping_mall:
            accuracy: 46.4
          street_pedestrian:
            accuracy: 55.5
          street_traffic:
            accuracy: 82.5
          tram:
            accuracy: 56.5

      device_B:
        # Overall accuracy, device B (mean of class-wise accuracies)
        overall:
          accuracy: 45.1

        # Class-wise accuracies
        class_wise:
          airport:
            accuracy: 68.9
          bus:
            accuracy: 70.6
          metro:
            accuracy: 23.9
          metro_station:
            accuracy: 33.9
          park:
            accuracy: 67.2
          public_square:
            accuracy: 22.8
          shopping_mall:
            accuracy: 58.3
          street_pedestrian:
            accuracy: 16.7
          street_traffic:
            accuracy: 69.4
          tram:
            accuracy: 18.9

      device_C:
        # Overall accuracy, device B (mean of class-wise accuracies)
        overall:
          accuracy: 46.2

        # Class-wise accuracies
        class_wise:
          airport:
            accuracy: 76.1
          bus:
            accuracy: 86.1
          metro:
            accuracy: 17.2
          metro_station:
            accuracy: 31.7
          park:
            accuracy: 51.1
          public_square:
            accuracy: 26.7
          shopping_mall:
            accuracy: 63.9
          street_pedestrian:
            accuracy: 25.0
          street_traffic:
            accuracy: 63.3
          tram:
            accuracy: 20.6

  public_leaderboard:
    # System score from public leaderboard (https://www.kaggle.com/c/dcase2018-task1b-leaderboard)
    overall:
      accuracy: 45.0

