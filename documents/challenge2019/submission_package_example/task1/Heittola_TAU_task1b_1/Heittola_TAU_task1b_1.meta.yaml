# Submission information
submission:
  # Submission label
  # Label is used to index submissions, to avoid overlapping codes among submissions
  # use following way to form your label:
  # [Last name of corresponding author]_[Abbreviation of institute of the corresponding author]_task[task number]_[index number of your submission (1-4)]
  label: Heittola_TAU_task1b_1

  # Submission name
  # This name will be used in the results tables when space permits
  name: DCASE2019 baseline system

  # Submission name abbreviated
  # This abbreviated name will be used in the results table when space is tight, maximum 10 characters
  abbreviation: Baseline

  # Submission authors in order, mark one of the authors as corresponding author.
  authors:
    # First author
    - lastname: Heittola
      firstname: Toni
      email: toni.heittola@tuni.fi                     # Contact email address
      corresponding: true                              # Mark true for one of the authors

      # Affiliation information for the author
      affiliation:
        abbreviation: TAU
        institute: Tampere University
        department: Computing Sciences
        location: Tampere, Finland

    # Second author
    - lastname: Mesaros
      firstname: Annamaria
      email: annamaria.mesaros@tuni.fi                 # Contact email address

      # Affiliation information for the author
      affiliation:
        abbreviation: TAU
        institute: Tampere University
        department: Computing Sciences
        location: Tampere, Finland

# System information
system:
  # System description, meta data provided here will be used to do
  # meta analysis of the submitted system. Use general level tags, if possible use the tags provided in comments.
  # If information field is not applicable to the system, use "!!null".
  description:

    # Audio input
    input_sampling_rate: 44.1kHz            #

    # Acoustic representation
    acoustic_features: log-mel energies   # e.g one or multiple [MFCC, log-mel energies, spectrogram, CQT, ...]

    # Data augmentation methods
    data_augmentation: !!null             # [time stretching, block mixing, pitch shifting, ...]

    # Machine learning
    # In case using ensemble methods, please specify all methods used (comma separated list).
    machine_learning_method: CNN          # e.g one or multiple [GMM, HMM, SVM, kNN, MLP, CNN, RNN, CRNN, NMF, random forest, ensemble, ...]

    # Ensemble method subsystem count
    # In case ensemble method is not used, mark !!null.
    ensemble_method_subsystem_count: !!null # [2, 3, 4, 5, ... ]

    # Decision making methods
    decision_making: !!null               # [majority vote, ...]

    # Method to deal with mismatched devices
    device_mismatch_handling: !!null      # [domain adaptation, transfer learning, feature transform, model adaptation, ... ]

    # External data usage method
    external_data_usage: !!null           # [directly, embeddings, pre-trained model, ...]

  # System complexity, meta data provided here will be used to evaluate
  # submitted systems from the computational load perspective.
  complexity:

    # Total amount of parameters used in the acoustic model. For neural networks, this
    # information is usually given before training process in the network summary.
    # For other than neural networks, if parameter count information is not directly available,
    # try estimating the count as accurately as possible.
    # In case of ensemble approaches, add up parameters for all subsystems.
    # Use numerical value.
    total_parameters: 116118

  # List of external datasets used in the submission. Development dataset is used here as example, list only external datasets
  external_datasets:
    # Dataset name
    - name: TAU Urban Acoustic Scenes 2019 Mobile, Development dataset

      # Dataset access url
      url: https://doi.org/10.5281/zenodo.2589332

      # Total audio length in minutes
      total_audio_length: 2760            # minutes

  # URL to the source code of the system [optional]
  source_code: https://github.com/toni-heittola/dcase2019_task1_baseline

# System results
results:
  # Full results are not mandatory, but for through analysis of the challenge submissions recommended.
  # If you cannot provide all results, also incomplete results can be reported.

  development_dataset:
    # System result for development dataset with provided the cross-validation setup.
    # Overall accuracy, average accuracy between device B and C (average of average class-wise accuracy)
    overall:
      accuracy: 41.4

    # Class-wise accuracies
    class_wise:
      airport:
        accuracy: 21.2
      bus:
        accuracy: 55.2
      metro:
        accuracy: 43.4
      metro_station:
        accuracy: 30.0
      park:
        accuracy: 51.1
      public_square:
        accuracy: 17.0
      shopping_mall:
        accuracy: 64.2
      street_pedestrian:
        accuracy: 37.3
      street_traffic:
        accuracy: 81.8
      tram:
        accuracy: 12.3

    device_wise:
      # Device wise results, three devices: A, B, C

      device_A:
        # Overall accuracy, device A (mean of class-wise accuracies)
        overall:
          accuracy: 61.9

        # Class-wise accuracies
        class_wise:
          airport:
            accuracy: 51.2
          bus:
            accuracy: 68.0
          metro:
            accuracy: 62.4
          metro_station:
            accuracy: 54.4
          park:
            accuracy: 80.4
          public_square:
            accuracy: 35.4
          shopping_mall:
            accuracy: 64.4
          street_pedestrian:
            accuracy: 63.3
          street_traffic:
            accuracy: 85.8
          tram:
            accuracy: 52.2

      device_B:
        # Overall accuracy, device B (mean of class-wise accuracies)
        overall:
          accuracy: 39.6

        # Class-wise accuracies
        class_wise:
          airport:
            accuracy: 18.3
          bus:
            accuracy: 40.4
          metro:
            accuracy: 50.7
          metro_station:
            accuracy: 28.7
          park:
            accuracy: 45.2
          public_square:
            accuracy: 22.8
          shopping_mall:
            accuracy: 63.5
          street_pedestrian:
            accuracy: 37.0
          street_traffic:
            accuracy: 77.0
          tram:
            accuracy: 12.0

      device_C:
        # Overall accuracy, device B (mean of class-wise accuracies)
        overall:
          accuracy: 43.1

        # Class-wise accuracies
        class_wise:
          airport:
            accuracy: 24.1
          bus:
            accuracy: 70.0
          metro:
            accuracy: 36.1
          metro_station:
            accuracy: 36.1
          park:
            accuracy: 57.0
          public_square:
            accuracy: 11.3
          shopping_mall:
            accuracy: 64.8
          street_pedestrian:
            accuracy: 37.6
          street_traffic:
            accuracy: 86.5
          tram:
            accuracy: 12.6

  public_leaderboard:
    # Team name used in public leaderboard (https://www.kaggle.com/c/dcase2019-task1b-leaderboard)
    team_name: DCASE2019 Task1A baseline

    # System score from public leaderboard (https://www.kaggle.com/c/dcase2019-task1b-leaderboard)
    overall:
      accuracy: 43.8

